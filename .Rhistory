runmodel("y", c("lag.quarterly.revenue"), dataset=freeny)
model_output(mods)
model_output <- function(models){
model <- models[[length(models)]]
### ASSUMPTIONS OUTPUT
#assumptions_check(model)
dw <- dwtest(model)$statistic
dwp <- dwtest(model)$p.value
#partplots <- avPlots(model)
residplot <- plot(predict(model), studres(model), main="Residuals by Predicted value", xlab="Unstandardized Predicted Values", ylab="Studentized Residuals")
cormat <- cor(data.frame(lapply(model.frame(model), as.numeric)), use="pairwise.complete.obs")
vifs <- vif(model)
standresids <- stdres(model)
cdists <- cooks.distance(model)
levplot <- leveragePlots(model)
residplot <- hist(standresids, prob=T, breaks = 30, main = "Plot of Std Residuals", xlab="Std Residuals")
normresids <- shapiro.test(standresids)$p.value
probDist <- pnorm(stdres(model))
cat("Durbin-Watson = ", dw, "p value = ", dwp, "\n")
cat("Partial Regression plots (all relationships should be linear):\n")
#partplots
#cat("Plot of studentized residuals (should be linear and homogenous across predicted values)\n")
residplot
cat("Correlation Matrix for model (correlation >.70 indicates severe multicollinearity)\n")
print(cormat)
cat("Variance inflation factor (<10 desired):\n")
print(vifs)
cat("Standardized Residuals (observations > 3.00 problematic):\n")
res <- sort(abs(standresids), decreasing = T)
print(res)
cat("Cook's distance (values >.2 problematic):\n")
print(sort(cdists, decreasing = T))
#cat("Leverage Plot\n")
levplot
#cat("Plot of standardized model residuals\n")
residplot
mean(stdres(model))
sd(stdres(model))
curve(dnorm(x,mean(stdres(model)), sd(stdres(model))), col="darkblue", lwd=2, add=TRUE, yaxt="n")
cat("Normality of standardized model residuals:", " Shapiro-Wilk (p-value): ", normresids, "\n")
#cat("PP plot:")
plot(ppoints(length(stdres(model))), sort(probDist), main = "PP Plot", xlab = "Observed Probability", ylab = "Expected Probability")
abline(0,1)
cat("Model change statistics\n")
### MODEL OUTPUT
for(i in 1:length(models) - 1){
modelCompare(models[[i]], models[[i + 1]])
}
cat("Model including all predictors\n")
summary(model)
}
Q
model_output <- function(models){
model <- models[[length(models)]]
### ASSUMPTIONS OUTPUT
#assumptions_check(model)
dw <- dwtest(model)$statistic
dwp <- dwtest(model)$p.value
#partplots <- avPlots(model)
residplot <- plot(predict(model), studres(model), main="Residuals by Predicted value", xlab="Unstandardized Predicted Values", ylab="Studentized Residuals")
cormat <- cor(data.frame(lapply(model.frame(model), as.numeric)), use="pairwise.complete.obs")
vifs <- vif(model)
standresids <- stdres(model)
cdists <- cooks.distance(model)
levplot <- leveragePlots(model)
residplot <- hist(standresids, prob=T, breaks = 30, main = "Plot of Std Residuals", xlab="Std Residuals")
normresids <- shapiro.test(standresids)$p.value
probDist <- pnorm(stdres(model))
cat("Durbin-Watson = ", dw, "p value = ", dwp, "\n")
cat("Partial Regression plots (all relationships should be linear):\n")
#partplots
#cat("Plot of studentized residuals (should be linear and homogenous across predicted values)\n")
residplot
cat("Correlation Matrix for model (correlation >.70 indicates severe multicollinearity)\n")
print(cormat)
cat("Variance inflation factor (<10 desired):\n")
print(vifs)
cat("Standardized Residuals (observations > 3.00 problematic):\n")
res <- sort(abs(standresids), decreasing = T)
print(res)
cat("Cook's distance (values >.2 problematic):\n")
print(sort(cdists, decreasing = T))
#cat("Leverage Plot\n")
levplot
#cat("Plot of standardized model residuals\n")
residplot
mean(stdres(model))
sd(stdres(model))
curve(dnorm(x,mean(stdres(model)), sd(stdres(model))), col="darkblue", lwd=2, add=TRUE, yaxt="n")
cat("Normality of standardized model residuals:", " Shapiro-Wilk (p-value): ", normresids, "\n")
#cat("PP plot:")
plot(ppoints(length(stdres(model))), sort(probDist), main = "PP Plot", xlab = "Observed Probability", ylab = "Expected Probability")
abline(0,1)
cat("Model change statistics\n")
### MODEL OUTPUT
for(i in 1:length(models) - 1){
modelCompare(models[[i]], models[[i + 1]])
}
cat("Model including all predictors\n")
summary(model)
}
model_output(mods)
model_output <- function(models){
model <- models[[length(models)]]
### ASSUMPTIONS OUTPUT
#assumptions_check(model)
dw <- dwtest(model)$statistic
dwp <- dwtest(model)$p.value
#partplots <- avPlots(model)
residplot <- plot(predict(model), studres(model), main="Residuals by Predicted value", xlab="Unstandardized Predicted Values", ylab="Studentized Residuals")
cormat <- cor(data.frame(lapply(model.frame(model), as.numeric)), use="pairwise.complete.obs")
vifs <- vif(model)
standresids <- stdres(model)
cdists <- cooks.distance(model)
levplot <- leveragePlots(model)
residplot <- hist(standresids, prob=T, breaks = 30, main = "Plot of Std Residuals", xlab="Std Residuals")
normresids <- shapiro.test(standresids)$p.value
probDist <- pnorm(stdres(model))
cat("Durbin-Watson = ", dw, "p value = ", dwp, "\n")
cat("Partial Regression plots (all relationships should be linear):\n")
#partplots
#cat("Plot of studentized residuals (should be linear and homogenous across predicted values)\n")
residplot
cat("Correlation Matrix for model (correlation >.70 indicates severe multicollinearity)\n")
print(cormat)
cat("Variance inflation factor (<10 desired):\n")
print(vifs)
cat("Standardized Residuals (observations > 3.00 problematic):\n")
res <- sort(abs(standresids), decreasing = T)
print(res)
cat("Cook's distance (values >.2 problematic):\n")
print(sort(cdists, decreasing = T))
#cat("Leverage Plot\n")
levplot
#cat("Plot of standardized model residuals\n")
residplot
mean(stdres(model))
sd(stdres(model))
curve(dnorm(x,mean(stdres(model)), sd(stdres(model))), col="darkblue", lwd=2, add=TRUE, yaxt="n")
cat("Normality of standardized model residuals:", " Shapiro-Wilk (p-value): ", normresids, "\n")
#cat("PP plot:")
plot(ppoints(length(stdres(model))), sort(probDist), main = "PP Plot", xlab = "Observed Probability", ylab = "Expected Probability")
abline(0,1)
cat("Model change statistics\n")
### MODEL OUTPUT
for(i in 1:(length(models) - 1)){
modelCompare(models[[i]], models[[i + 1]])
}
cat("Model including all predictors\n")
summary(model)
}
model_output <- function(models){
model <- models[[length(models)]]
### ASSUMPTIONS OUTPUT
#assumptions_check(model)
dw <- dwtest(model)$statistic
dwp <- dwtest(model)$p.value
#partplots <- avPlots(model)
residplot <- plot(predict(model), studres(model), main="Residuals by Predicted value", xlab="Unstandardized Predicted Values", ylab="Studentized Residuals")
cormat <- cor(data.frame(lapply(model.frame(model), as.numeric)), use="pairwise.complete.obs")
vifs <- vif(model)
standresids <- stdres(model)
cdists <- cooks.distance(model)
levplot <- leveragePlots(model)
residplot <- hist(standresids, prob=T, breaks = 30, main = "Plot of Std Residuals", xlab="Std Residuals")
normresids <- shapiro.test(standresids)$p.value
probDist <- pnorm(stdres(model))
cat("Durbin-Watson = ", dw, "p value = ", dwp, "\n")
cat("Partial Regression plots (all relationships should be linear):\n")
#partplots
#cat("Plot of studentized residuals (should be linear and homogenous across predicted values)\n")
residplot
cat("Correlation Matrix for model (correlation >.70 indicates severe multicollinearity)\n")
print(cormat)
cat("Variance inflation factor (<10 desired):\n")
print(vifs)
cat("Standardized Residuals (observations > 3.00 problematic):\n")
res <- sort(abs(standresids), decreasing = T)
print(res)
cat("Cook's distance (values >.2 problematic):\n")
print(sort(cdists, decreasing = T))
#cat("Leverage Plot\n")
levplot
#cat("Plot of standardized model residuals\n")
residplot
mean(stdres(model))
sd(stdres(model))
curve(dnorm(x,mean(stdres(model)), sd(stdres(model))), col="darkblue", lwd=2, add=TRUE, yaxt="n")
cat("Normality of standardized model residuals:", " Shapiro-Wilk (p-value): ", normresids, "\n")
#cat("PP plot:")
plot(ppoints(length(stdres(model))), sort(probDist), main = "PP Plot", xlab = "Observed Probability", ylab = "Expected Probability")
abline(0,1)
cat("Model change statistics\n")
### MODEL OUTPUT
for(i in 1:(length(models) - 1)){
modelCompare(models[[i]], models[[i + 1]])
}
cat("Model including all predictors\n")
summary(model)
}
model_output(mods)
install.packages("ggplot2")
getwd()
setwd("/media/alex/Windows8_OS/Documents and Settings/Alex/Documents/R")
wipro <- read.csv("MSU_Wipro_Urban_STEM_Application_20152016.csv", header=F)
install.packages("ggplot2")
library(ggplot2)
likert_cats <- c(
"1: Beginner",
"2",
"3: Intermediate",
"4",
"5: Expert"
)
props <- table(wipro$V49) / 241
gradedata <- data.frame(props, likert_cats)
pie <- ggplot(gradedata, aes(x=factor(1), y=gradedata$Freq, fill=factor(gradedata$likert_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
pie <- pie + coord_polar(theta="y")
pie = pie + ylab('Grade Breakdown of Applicants') + xlab('') + labs(fill='Race')
pie
likert_cats <- c(
"1: Beginner",
"2",
"3: Intermediate",
"4",
"5: Expert"
)
props <- table(wipro$V49) / 241
gradedata <- data.frame(props, likert_cats)
pie <- ggplot(gradedata, aes(x=factor(1), y=gradedata$Freq, fill=factor(gradedata$likert_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
pie <- pie + coord_polar(theta="y")
pie = pie + ylab('') + xlab('') + labs(fill='') + ggtitle("On a scale of 1 to 5 Rate your current technical expertise.")
pie
likert_cats <- c(
"1: Beginner",
"2",
"3: Intermediate",
"4",
"5: Expert"
)
props <- table(wipro$V49) / 241
gradedata <- data.frame(props, likert_cats)
pie <- ggplot(gradedata, aes(x=factor(1), y=gradedata$Freq, fill=factor(gradedata$likert_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
#pie <- pie + coord_polar(theta="y")
pie = pie + ylab('') + xlab('') + labs(fill='') + ggtitle("On a scale of 1 to 5 Rate your current technical expertise.")
pie
likert_cats <- c(
"1: I never adopt it.",
"2",
"3: I adopt it when it becomes mainstream.",
"4",
"5: I'm one of the first to try it."
)
props <- table(wipro$V51) / 241
gradedata <- data.frame(props, likert_cats)
pie <- ggplot(gradedata, aes(x=factor(1), y=gradedata$Freq, fill=factor(gradedata$likert_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
#pie <- pie + coord_polar(theta="y")
pie = pie + ylab('') + xlab('') + labs(fill='') + ggtitle("On a scale of 1 to 5 Rate yourself as an adopter of new technology.")
pie
likert_cats <- c(
"1: Beginner",
"2",
"3: Intermediate",
"4",
"5: Expert"
)
props <- table(wipro$V49) / 241
gradedata <- data.frame(props, likert_cats)
pie <- ggplot(gradedata, aes(x=factor(1), y=gradedata$Freq, fill=factor(gradedata$likert_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
#pie <- pie + coord_polar(theta="y")
pie = pie + ylab('') + xlab('') + labs(fill='') + ggtitle("On a scale of 1 to 5 Rate your current technical expertise.")
pie
likert_cats <- c(
"1: Consumer",
"2",
"3: Producer",
"4",
"5: Activist"
)
props <- table(wipro$V50) / 241
gradedata <- data.frame(props, likert_cats)
pie <- ggplot(gradedata, aes(x=factor(1), y=gradedata$Freq, fill=factor(gradedata$likert_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
#pie <- pie + coord_polar(theta="y")
pie = pie + ylab('') + xlab('') + labs(fill='') + ggtitle("On a scale of 1 to 5 Rate your current digital and media literacy.")
pie
props <- table(wipro$V51) / 241
props
typeof(props)
props[4]
props <- double(0)
props
props <- table(wipro$V51) / 241
props <- double(0) + props
props
props <- table(wipro$V51) / 241
props <- double(0,props)
props
props[0]
props[0] <- 0
props
wipro$V51
levels(wipro$V51)
is.factor(wipro$V51)
as.factor(wipro$V51)
levels(as.factor(wipro$V51))
levels(as.factor(wipro$V51)) <- ("1", "2", "3", "4", "5")
levels(as.factor(wipro$V51)) <- c("1", "2", "3", "4", "5")
wiprov51 <- as.factor(wipro$V51)
levels(wiprov51)  <- c("1", "2", "3", "4", "5")
wiprov51
props <- table(wiprov51) / 241
props
as.factor(wipro$V51)
wiprov51
c(2:17, "AUSL")
c(2:17, "17")
c(2:16, "17")
table(wipro[,44])
network_cats <- c(2:16, "17")
props <- table(wipro[,44]) / 241
racedata <- data.frame(props, race_cats)
pie <- ggplot(racedata, aes(x=factor(1), y=racedata$Freq, fill=factor(racedata$race_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
pie <- pie + coord_polar(theta="y")
pie = pie + ylab('Applicants by network') + xlab('') + labs(fill='')
pie
table(wipro[,44])
network_cats <- c(2:16, "17")
props <- table(wipro[,44]) / 241
racedata <- data.frame(props, network_cats)
pie <- ggplot(racedata, aes(x=factor(1), y=racedata$Freq, fill=factor(racedata$network_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
pie <- pie + coord_polar(theta="y")
pie = pie + ylab('Applicants by network') + xlab('') + labs(fill='')
pie
table(wipro[,44])
network_cats <- c(2:16, "17")
props <- table(wipro[,44]) / 241
racedata <- data.frame(props, network_cats)
pie <- ggplot(racedata, aes(x=factor(1), y=racedata$Freq, fill=factor(racedata$network_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
#pie <- pie + coord_polar(theta="y")
pie = pie + ylab('Applicants by network') + xlab('') + labs(fill='')
pie
table(wipro[,44])
network_cats <- c(2:16, "17")
props <- table(wipro[,44]) / 241
racedata <- data.frame(props, network_cats)
pie <- ggplot(racedata, aes(x=factor(1), y=racedata$Freq, fill=factor(racedata$network_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
#pie <- pie + coord_polar(theta="y")
pie = pie + ylab('') + xlab('') + labs(fill='') + ggtitle("Applicants by Network")
pie
network_cats <- c(02, 03, 04, 05, 06, 07, 08, 09, 10:16, "17")
props <- table(wipro[,44]) / 241
racedata <- data.frame(props, network_cats)
pie <- ggplot(racedata, aes(x=factor(1), y=racedata$Freq, fill=factor(racedata$network_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
#pie <- pie + coord_polar(theta="y")
pie = pie + ylab('') + xlab('') + labs(fill='') + ggtitle("Applicants by Network")
pie
network_cats <- c("02", "03", "04", "05", "06", "07", "08", "09", 10:16, "17")
props <- table(wipro[,44]) / 241
racedata <- data.frame(props, network_cats)
pie <- ggplot(racedata, aes(x=factor(1), y=racedata$Freq, fill=factor(racedata$network_cats)),)
pie <- pie + geom_bar(width=1, stat="identity")
#pie <- pie + coord_polar(theta="y")
pie = pie + ylab('') + xlab('') + labs(fill='') + ggtitle("Applicants by Network")
pie
install.packages("roxygen")
R.version()
install.packages("roxygen")
install.packages("devtools")
install.package('roxygen2')
install.packages('roxygen2')
library(devtools, roxygen2)
library(devtools)
install.packages("devtools")
install.packages('RCurl')
install.packages(c("knitr", "Rcpp", "RcppArmadillo", "rmarkdown", "stringr"))
install.packages('RCurl')
locate libcurl
install.packages('libcurl')
install.packages('RCurl')
install.packages('libcurl')
install.packages("devtools")
install.packages("roxygen2")
library(dplyr)
create_model_objects("y", c("lag.quarterly.revenue"), dataset=freeny)
### Main model function
runmodel <- function(outcome, block1, ..., dataset, transform.outcome=F){
forms <- create_formula_objects(outcome, block1, ...)
models <- create_model_objects(forms, dataset)
top_model <- models[[length(models)]]
model_output(models)
}
### Creates formulas for hierarchical models
create_formula_objects <- function(outcome, block1, ...){
blocks <- list(...)
formula <- as.formula(paste(outcome, "~", paste(block1, collapse="+")))
formulas <- list()
if(length(blocks) != 0){
formulas <- list(formula)
for(block in blocks){
formulas[[length(formulas) + 1]] <-  as.formula(paste(formulas[length(formulas)], "+", paste(block, collapse="+")))
}
}
if(length(formulas) == 0){
formula
} else {
formulas
}
}
create_formula_objects("y", "abc", c("a", "b", "c"))
create_model_objects <- function(formulas, dataset){
models <- lapply(X = forms, data=freeny, lm)
}
mods <- create_model_objects(forms, freeny)
create_model_objects("y", c("lag.quarterly.revenue"), dataset=freeny)
runmodel("y", c("lag.quarterly.revenue"), c("price.index", "income.level"), dataset=freeny)
create_formula_objects("y", c("lag.quarterly.revenue"), c("price.index", "income.level"))
forms <- create_formula_objects("y", c("lag.quarterly.revenue"), c("price.index", "income.level"))
mods <- create_model_objects(forms, freeny)
mods
assumptions_check(mods[[2]])
model_output(mods)
assumptions_check <- function(model){
### GATHERING INFORMATION FOR ASSUMPTION CHECKING
dw <- dwtest(model)$statistic
dwp <- dwtest(model)$p.value
#partplots <- avPlots(model)
residplot <- plot(predict(model), studres(model), main="Residuals by Predicted value", xlab="Unstandardized Predicted Values", ylab="Studentized Residuals")
cormat <- cor(data.frame(lapply(model.frame(model), as.numeric)), use="pairwise.complete.obs")
vifs <- vif(model)
standresids <- stdres(model)
cdists <- cooks.distance(model)
levplot <- leveragePlots(model)
residplot <- hist(standresids, prob=T, breaks = 30, main = "Plot of Std Residuals", xlab="Std Residuals")
normresids <- shapiro.test(standresids)$p.value
probDist <- pnorm(stdres(model))
}
model_output <- function(models){
model <- models[[length(models)]]
### ASSUMPTIONS OUTPUT
#assumptions_check(model)
dw <- dwtest(model)$statistic
dwp <- dwtest(model)$p.value
#partplots <- avPlots(model)
residplot <- plot(predict(model), studres(model), main="Residuals by Predicted value", xlab="Unstandardized Predicted Values", ylab="Studentized Residuals")
cormat <- cor(data.frame(lapply(model.frame(model), as.numeric)), use="pairwise.complete.obs")
vifs <- vif(model)
standresids <- stdres(model)
cdists <- cooks.distance(model)
levplot <- leveragePlots(model)
residplot <- hist(standresids, prob=T, breaks = 30, main = "Plot of Std Residuals", xlab="Std Residuals")
normresids <- shapiro.test(standresids)$p.value
probDist <- pnorm(stdres(model))
cat("Durbin-Watson = ", dw, "p value = ", dwp, "\n")
cat("Partial Regression plots (all relationships should be linear):\n")
#partplots
#cat("Plot of studentized residuals (should be linear and homogenous across predicted values)\n")
residplot
cat("Correlation Matrix for model (correlation >.70 indicates severe multicollinearity)\n")
print(cormat)
cat("Variance inflation factor (<10 desired):\n")
print(vifs)
cat("Standardized Residuals (observations > 3.00 problematic):\n")
res <- sort(abs(standresids), decreasing = T)
print(res)
cat("Cook's distance (values >.2 problematic):\n")
print(sort(cdists, decreasing = T))
#cat("Leverage Plot\n")
levplot
#cat("Plot of standardized model residuals\n")
residplot
mean(stdres(model))
sd(stdres(model))
curve(dnorm(x,mean(stdres(model)), sd(stdres(model))), col="darkblue", lwd=2, add=TRUE, yaxt="n")
cat("Normality of standardized model residuals:", " Shapiro-Wilk (p-value): ", normresids, "\n")
#cat("PP plot:")
plot(ppoints(length(stdres(model))), sort(probDist), main = "PP Plot", xlab = "Observed Probability", ylab = "Expected Probability")
abline(0,1)
cat("Model change statistics\n")
### MODEL OUTPUT
for(i in 1:(length(models) - 1)){
modelCompare(models[[i]], models[[i + 1]])
}
cat("Model including all predictors\n")
summary(model)
}
model_output(mods)
library(lmtest)
library(datasets)
library(MASS)
assumptions_check(mods[[2]])
model_output(mods)
capabilities()
assumptions_check(mods[[2]])
model_output(mods)
cpabilities()
capabilities()
install.packages("stringr")
library(stringr)
plot(freeny$lag.quarterly.revenue, freeny$price.index)
capabilities()
capabilities()
